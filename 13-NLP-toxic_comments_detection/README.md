# Детекция токсичных комментарием
[IPYNB](https://github.com/lil-scripter/practicum_projects/blob/d36734b8d4f6986487ad0283a8357f849ee1a5b8/13-NLP-toxic_comments_detection/13-NLP-toxic_comments_detection.ipynb)

## Описание проекта

Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

В распоряжении набор данных с разметкой о токсичности правок. Столбец text содержит текст комментария, а toxic — целевой признак.

Цель

Обучить модель, которая будет классифицировать комментарии на позитивные и негативные.

Задача

Постройте модель со значением метрики качества F1 не меньше 0.75.

## Стек
pandas, sklearn, numpy, nltk, transformers, tqdm

## Общий вывод

Для подготовки обучающих выборок использовали 2 типа подготовки текста: TF-IDF векторизация с учетом частей речи, ембеддинги BERT.

Обучено 2 типа моделей с подбором гиперпараметров: логистическая регрессия, рандомный лес. 

Модели, обученные на ембеддингах BERT, лучше детектируют токсичные комментарии. Модель рандомного леса справилась с тренироовочной выборкой лучше всех остальных. Для уменьшения влияния переобучения на тренировочных данных модель была дообучена.

Метрика F1 лучшей модели на тестовой выборке составила 0.96.
